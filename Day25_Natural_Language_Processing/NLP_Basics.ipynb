{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hpbStDWjfDxu"
      },
      "outputs": [],
      "source": [
        "import nltk,spacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') #handle multiple languages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1aHMyhWgO2x",
        "outputId": "a2658d96-9f5a-4551-aa6a-bff38715ab6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "our_text=\"Artificial Intelligence and Machine Learning are going to change the future of technology!\""
      ],
      "metadata": {
        "id": "8g1uaRv6g3UZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize\n",
        "#splits text into individual words/tokens\n",
        "\n",
        "tokens=nltk.word_tokenize(our_text)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp_NJQVphjlO",
        "outputId": "44fb25f3-c4c3-4599-9814-1fec9a71d892"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Artificial',\n",
              " 'Intelligence',\n",
              " 'and',\n",
              " 'Machine',\n",
              " 'Learning',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'change',\n",
              " 'the',\n",
              " 'future',\n",
              " 'of',\n",
              " 'technology',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning\n",
        "\n",
        "clean_tokens=[re.sub('[^a-zA-Z]','', token.lower()) for token in tokens if token.isalpha()]\n",
        "clean_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cScH1_TRjqCC",
        "outputId": "b19d2858-0469-4e53-d071-f221de12a1e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial',\n",
              " 'intelligence',\n",
              " 'and',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'change',\n",
              " 'the',\n",
              " 'future',\n",
              " 'of',\n",
              " 'technology']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stop word removal,removes unsignificance words\n",
        "\n",
        "stop_words=set(stopwords.words('english'))\n",
        "filtered_tokens = [token for token in clean_tokens if token not in stop_words]\n",
        "filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJHA37hMktPZ",
        "outputId": "33880f8a-d6ca-4bf4-b047-8ac772314bca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial',\n",
              " 'intelligence',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'going',\n",
              " 'change',\n",
              " 'future',\n",
              " 'technology']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "#Reduce the words to their root form (not always a word from dictionary)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens=[stemmer.stem(token) for token in filtered_tokens]\n",
        "stemmed_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1dKrIVElcy8",
        "outputId": "985ad41e-f6a7-44d7-a2e6-19d124e07623"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artifici',\n",
              " 'intellig',\n",
              " 'machin',\n",
              " 'learn',\n",
              " 'go',\n",
              " 'chang',\n",
              " 'futur',\n",
              " 'technolog']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatization\n",
        "#Convert words to their dictionary form (lemma) using POS (part of speech)\n",
        "\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "lemmatized_tokens=[lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYxQNfE2mZwB",
        "outputId": "be64299d-37da-44ca-8ec6-5e70875df4f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial',\n",
              " 'intelligence',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'going',\n",
              " 'change',\n",
              " 'future',\n",
              " 'technology']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bag of Words (BOW)"
      ],
      "metadata": {
        "id": "Njdw4z8cnz8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[\n",
        "\"Ariticial Intelligence is transforming Industries\",\n",
        "\"Machine Learning is a branch of artificial intelligence\",\n",
        "\"Deep Learning is a subfield of machine learning\",\n",
        "\"Natural Language Processing is a subfield of artificial intelligence\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "ats93ybNnIwI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv=CountVectorizer()\n",
        "bow_m=cv.fit_transform(corpus)\n",
        "\n",
        "print(\"********Features Names (BOW)********\")\n",
        "print(cv.get_feature_names_out())\n",
        "print(\"\\n********BOW Matrix Array********\")\n",
        "print(bow_m.toarray())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZzSO1Kmoa2h",
        "outputId": "30b01e53-c21d-4403-efb1-16cc10108d73"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********Features Names (BOW)********\n",
            "['ariticial' 'artificial' 'branch' 'deep' 'industries' 'intelligence' 'is'\n",
            " 'language' 'learning' 'machine' 'natural' 'of' 'processing' 'subfield'\n",
            " 'transforming']\n",
            "\n",
            "********BOW Matrix Array********\n",
            "[[1 0 0 0 1 1 1 0 0 0 0 0 0 0 1]\n",
            " [0 1 1 0 0 1 1 0 1 1 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 2 1 0 1 0 1 0]\n",
            " [0 1 0 0 0 1 1 1 0 0 1 1 1 1 0]]\n"
          ]
        }
      ]
    }
  ]
}